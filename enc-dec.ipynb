{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4e60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a514be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sent):\n",
    "    sent = sent.lower().strip()\n",
    "    sent = re.sub(r\"[^a-zA-Zँ-९\\s]\", \"\", sent)  # keep Nepali Devanagari + Latin\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b26212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    eng_sentences = []\n",
    "    nep_sentences = []\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                eng= clean_sentence(parts[0])\n",
    "                nep = clean_sentence(parts[1])\n",
    "                eng_sentences.append(eng)\n",
    "                nep_sentences.append(nep)\n",
    "\n",
    "    return eng_sentences, nep_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e9f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sentences, nep_sentences = load_dataset(\"data/npi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58734e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eng: who\n",
      "Nep: को\n",
      "\n",
      "Eng: hide\n",
      "Nep: लुकाउनुहोस्।\n",
      "\n",
      "Eng: hide\n",
      "Nep: लुक।\n",
      "\n",
      "Eng: stay\n",
      "Nep: बस्नुहोस्।\n",
      "\n",
      "Eng: hello\n",
      "Nep: नमस्ते\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Eng: {eng_sentences[i]}\")\n",
    "    print(f\"Nep: {nep_sentences[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9210850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "def tokenize(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "eng_tokens = [tokenize(sent) for sent in eng_sentences]\n",
    "nep_tokens = [tokenize(sent) for sent in nep_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd303c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eng tokens: ['who']\n",
      "Nep tokens: ['को']\n",
      "\n",
      "Eng tokens: ['hide']\n",
      "Nep tokens: ['लुकाउनुहोस्।']\n",
      "\n",
      "Eng tokens: ['hide']\n",
      "Nep tokens: ['लुक।']\n",
      "\n",
      "Eng tokens: ['stay']\n",
      "Nep tokens: ['बस्नुहोस्।']\n",
      "\n",
      "Eng tokens: ['hello']\n",
      "Nep tokens: ['नमस्ते']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the tokens\n",
    "for i in range(5):\n",
    "    print(f\"Eng tokens: {eng_tokens[i]}\")\n",
    "    print(f\"Nep tokens: {nep_tokens[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec447456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the vocabulary\n",
    "\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "SOS_TOKEN = \"<SOS>\"\n",
    "EOS_TOKEN = \"<EOS>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "def build_vocab(token_lists, min_freq=1):\n",
    "    counter = Counter(token for tokens in token_lists for token in tokens)\n",
    "    vocab = {PAD_TOKEN: 0, SOS_TOKEN: 1, EOS_TOKEN: 2, UNK_TOKEN: 3}\n",
    "    for token, freq in counter.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[token] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "eng_vocab = build_vocab(eng_tokens)\n",
    "nep_vocab = build_vocab(nep_tokens)\n",
    "\n",
    "# Reverse vocab for decoding later\n",
    "inv_eng_vocab = {i: w for w, i in eng_vocab.items()}\n",
    "inv_nep_vocab = {i: w for w, i in nep_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2532e3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample English vocab: [('<PAD>', 0), ('<SOS>', 1), ('<EOS>', 2), ('<UNK>', 3), ('who', 4), ('hide', 5), ('stay', 6), ('hello', 7), ('smile', 8), ('attack', 9)]\n",
      "Sample Nepali vocab: [('<PAD>', 0), ('<SOS>', 1), ('<EOS>', 2), ('<UNK>', 3), ('को', 4), ('लुकाउनुहोस्।', 5), ('लुक।', 6), ('बस्नुहोस्।', 7), ('नमस्ते', 8), ('मुस्कान।', 9)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample English vocab:\", list(eng_vocab.items())[:10])\n",
    "print(\"Sample Nepali vocab:\", list(nep_vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ade3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_ids(tokens, vocab):\n",
    "    return [vocab.get(token, vocab[UNK_TOKEN]) for token in tokens]\n",
    "\n",
    "def wrap_sos_eos(ids, vocab):\n",
    "    return [vocab[SOS_TOKEN]] + ids + [vocab[EOS_TOKEN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ae298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original English: ['who']\n",
      "Token IDs: [1, 4, 2]\n",
      "Back to words: ['<SOS>', 'who', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "sample_eng_ids = wrap_sos_eos(sentence_to_ids(eng_tokens[0], eng_vocab), eng_vocab)\n",
    "sample_nep_ids = wrap_sos_eos(sentence_to_ids(nep_tokens[0], nep_vocab), nep_vocab)\n",
    "\n",
    "print(\"Original English:\", eng_tokens[0])\n",
    "print(\"Token IDs:\", sample_eng_ids)\n",
    "print(\"Back to words:\", [inv_eng_vocab[i] for i in sample_eng_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b0219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
